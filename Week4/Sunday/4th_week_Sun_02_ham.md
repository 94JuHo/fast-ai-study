참고 : https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb

# 04. Under the Hood: Training a Digit Classifier
# 04. 내부 살펴보기: 숫자 분류 학습 

## Computing Metrics Using Broadcasting
## 브로드캐스팅을 이용한 메트릭 계산

메트릭은 우리가 만든 모델의 예측과 올바르게 라벨링된 데이터셋에 기반하여 우리의 모델이 얼마나 잘만들어졌는지 알려준다. 
예를 들어, 앞에서 봤던 두가지 함수 평균 제곱 오차와 평균 절대 오차를 사용하여 모든 데이터셋에 걸친 평균을 구할 수 있다. 
하지만 이 두가지 수치들은 모두 대부분의 사람들이 쉽게 이해하기 쉽지 않다.; 
따라서 실제로는 보통 정확도를 분류 모델의 측정 기준으로 사용한다.

우리는 검증셋을 가지고 메트릭을 계산하고자 한다. 기존 데이터를 사용하지 않고 따로 검증셋을 두고 하는 이유는 오버핏을 하여 
학습 데이터에만 동작하도록 하는 것을 피하기 위해서이다. 여기서 처음에 했었던 픽셀 유사 모델에서는 학습된 컴포넌트들이 
없기 때문에 오버핏될 위험도가 별로 없긴 하다. 그래도 일반적인 절차에 따라서 검증 셋을 사용여 두번째 실습을 시작해 보자.

검증셋을 준비하려면 일단 학습 전체에서 데이터 일부를 제거하고, 모델이 접해보지 않은 데이터를 준비해야 한다. 다행히 MNIST 
데이터셋 제작자들이 이미 준비해놓은 것이 있어서 그것을 사용하기로 하자. 이전 예제에서 valid라고 따로 분리되어 있던 디렉토리가 
검증셋이다.

우선, 3과 7의 디렉토리로 텐서를 만들어보자. 이 텐서들을 사용해서 이상적인 이미지와의 차이를 가지고 우리가 처음 만들었던 
모델의 품질 메트릭을 계산해보기로 한다.

```python
valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])
valid_3_tens = valid_3_tens.float()/255
valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])
valid_7_tens = valid_7_tens.float()/255
valid_3_tens.shape,valid_7_tens.shape
```
```python
(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))
```

작업할 때마다 shapre를 체크하는 습관을 들이면 좋다. 여기에 두 텐서가 있다. 하나는 3의 검증셋인데 28x28 크기의 이미지 1,010개를 나타내며 또 하나는 7의 검증셋으로 역시 28x28 크기의 이미지 1,028개를 나타내고 있다.

우리는 임의의 이미지를 넣었을 때 3인지 7인지 알려주는 is_3 함수를 만들고자 한다. 이 함수는 주어진 임의의 이미지가 우리의 두가지 "이상적인 숫자" 중 어느쪽에 더 가까운지를 알려줄 것이다. 이를 위해서 두 이미지 간의 거리를 계산할 수 있도록 함수를 정의해야 한다.

우리는 앞의 세션에서 사용했던 것과 매우 유사한 식을 사용하여 평균 절대 오차를 계산하는 간단한 함수를 다음과 같이 만들어 볼 수 있다:

```python
def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))
mnist_distance(a_3, mean3)
```
```python
tensor(0.1114)
```

위 결과는 이전에 두 이미지들의 거리를 계산한 것과 같은 결과이다. 이 두 이미지들 이상적인 3인 `mean_3`과 임의의 샘플 3인 `a_3`은 `[28,28]` shape의 단일 이미지 텐서이다.

하지만 전체 정확도 메트릭을 계산하려면, 우리는 이상적인 3과 검증셋의 모든 이미지 간의 거리를 계산해야 한다. 어떻게 계산하면 좋을까? 검증셋 텐서에 스택된 모든 단일 이미지 텐서에 대해서 반복을 하도록 코드를 작성해볼 수 있는데, 여기서 검증셋 텐서 valid_3_tens는 [1010,28,28] shape를 가지고 1,010개의 이미지를 나타낸다. 그런데 이 방법보다 더 좋은 방법이 있다.

두 개의 단이일 이미지를 비교하기 위해 만들어진 거리 함수에 인자로 3의 검증셋인 valid_3_tens 텐서를 넣어보자. 그러면 매우 놀라운 결과가 일어난다.

```python
valid_3_dist = mnist_distance(valid_3_tens, mean3)
valid_3_dist, valid_3_dist.shape
```
```python
(tensor([0.1290, 0.1223, 0.1380,  ..., 0.1337, 0.1132, 0.1097]), torch.Size([1010]))
 ```
 인자가 매개변수 shape에 맞지않다는 에러 메시지 대신 모든 단일 이미지의 거리를 1,010개의 벡터(rank-1 텐서라고도 한다.)로 돌려주고 있다. 어떻게 된 것일까?
 
 `mnist_distance` 함수를 다시 살펴보면 빼기 `(a-b)`가 있음을 알 수 있다. 마술은 PyTorch가 다른 순위의 두 텐서 사이에서 간단한 빼기 연산을 수행하려고 할 때 broadcasting 이 이루어진다는 것에 있다. 즉, 랭크가 작은 텐서를 자동으로 확장하여 랭크가 큰 텐서를 같은 크기로 만든다. 브로드캐스팅은 텐서 코드를 훨씬 쉽게 작성할 수 있도록하는 중요한 기능이다.
 
 두 개의 인수 텐서가 동일한 rank를 가지도록 브로드 캐스팅 한 후, PyTorch는 동일한 rank의 두 텐서에 대해 일반적인 로직을 적용한다. 즉, 두 개의 텐서의 각 해당 요소에 대해 연산을 수행하고 텐서 결과를 반환하는 것이다. 예를 들면 다음과 같다.
 
 ```python
 tensor([1,2,3]) + tensor([1,1,1])
 ```
 ```python
 tensor([2, 3, 4])
 ```
 
 따라서 이 경우 PyTorch는 단일 이미지를 나타내는 rank-2 텐서인 'mean3'을 동일한 이미지의 1,010 개 사본 인 것처럼 처리 한 다음 검증셋 각각의 3 이미지에서 각 사본을 뺐다. 이 텐서는 어떤 shape를 가질 것이라 예상하는가? 아래 답변을 보기 전에 먼저 스스로 예측해보자.
 
```python
(valid_3_tens-mean3).shape
```
```python
torch.Size([1010, 28, 28])
```


# List
| | Part | Page | Speaker 1 | Speaker 2 |
|:-:|:-----:|:----:|:---------:|:---------:|
|1|[Pixels: The Foundations of Computer Vision](#1-1)|133|전준용| |
|1|[First Try: Pixel Similarity:NumPy Arrays and PyTorch Tensors](#1-2)|145|전준용| |
|2|[Computing Metrics Using Broadcastingn](#2-1)|145|함기훈| |
|2|[Stochastic Gradient Descent:Calculating Gradients](#2-2)|156|함기훈| |
|3|[Stochastic Gradient Descent:Stepping with a Learning Rate](#3-1)|157|김지은| |
|3|[Stochastic Gradient Descent:Summarizing Gradient Descent](#3-2)|163|김지은| |
|4|[The MNIST Loss Function:Sigmoid](#4-1)|163|최민영| |
|4|[The MNIST Loss Function:SGD and Mini-Batches](#4-2)|171|최민영| |
|5|[Putting It All Together:Creating an Optimizer](#5-1)|171|조윤희| |
|5|[Questionnaire:Further Research](#5-2)|184|조윤희| |



---

<div id="1-1"></div>
<div id="1-2"></div>

#### 1-1. Pixels: The Foundations of Computer Vision / 1-2. First Try: Pixel Similarity:NumPy Arrays and PyTorch Tensors
* 발표자료 : [전준용]()

    

<div id="2-1"></div>
<div id="2-2"></div>
    
#### 2-1. Computing Metrics Using Broadcasting / 2-2. Stochastic Gradient Descent:Calculating Gradients
* 발표자료 : [함기훈]()
    


<div id="3-1"></div>
<div id="3-2"></div>

#### 3-1. Stochastic Gradient Descent:Stepping with a Learning Rate / 3-2. Stochastic Gradient Descent:Summarizing Gradient Descent
* 발표자료 : [김지은]()
    




<div id="4-1"></div>
<div id="4-2"></div>

#### 4-1. The MNIST Loss Function:Sigmoid / 4-2. The MNIST Loss Function:SGD and Mini-Batches
* 발표자료 : [최민영]()
    






### 5-1. Putting It All Together:Creating an Optimizer / 5-2. Questionnaire:Further Research
* 발표자료 : [조윤희]()
  